{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "response = openai.Embedding.create(\n",
    "    input=\"Kobe Bryant\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "embedding1 = response['data'][0]['embedding']\n",
    "\n",
    "response = openai.Embedding.create(\n",
    "    input=\"Micheal Jordan\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "embedding2 = response['data'][0]['embedding']\n",
    "\n",
    "cosine_similarity(embedding1, embedding2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "from os.path import join\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from column_annotation_gnn.data_loader.SportsDB_data_loader import get_LabelEncoder\n",
    "\n",
    "label_enc = get_LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport-Domains / Tablewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data for gpt\n",
    "sport_domains = [\"baseball\", \"basketball\", \"football\", \"hockey\", \"soccer\"]\n",
    "#sport_domains = [\"baseball\"]\n",
    "shuffle_cols = False\n",
    "random_state = 1\n",
    "split = \"train\"\n",
    "number_of_rows_per_table = 10\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,6):\n",
    "    for sport_domain in sport_domains:\n",
    "        training_data_prompts = []\n",
    "        all_class_labels = []\n",
    "        # load metadata.json containing semantic types of the columns\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, \"metadata.json\")) as f:\n",
    "            metadata = json.load(f)\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, f\"train_valid_test_split_{random_state}.json\")) as f:\n",
    "                    train_valid_test_split = json.load(f)\n",
    "                    \n",
    "        for idx_table_path, table_name_full in enumerate(train_valid_test_split[split]):\n",
    "            training_data = {}\n",
    "            # if idx_table_path > 0:\n",
    "            #     continue\n",
    "            table_name = table_name_full.split(\"/\")[-1].split(\".csv\")[0]\n",
    "            ## search for correct in key in metadata\n",
    "            table_metadata_key = None\n",
    "            for key in metadata.keys():\n",
    "                if key in table_name:\n",
    "                    table_metadata_key = key\n",
    "            if table_metadata_key == None:\n",
    "                print(f\"CSV {table_name_full} not in metadata.json defined!\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(join(os.environ[\"SportsTables\"], sport_domain, table_name_full))\n",
    "            valid_cols = []\n",
    "            valid_labels = []\n",
    "            if shuffle_cols:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                #random.seed(self.random_state)\n",
    "                random.shuffle(column_list)\n",
    "            else:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                \n",
    "            for i in column_list:\n",
    "                column_name = df.columns[i]\n",
    "                # search for defined columns data type and semantic label in metadata\n",
    "                if column_name in metadata[table_metadata_key][\"textual_cols\"].keys():\n",
    "                    column_data_type = \"textual\"\n",
    "                    column_label = metadata[table_metadata_key][\"textual_cols\"][column_name]\n",
    "                elif column_name in metadata[table_metadata_key][\"numerical_cols\"].keys():\n",
    "                    column_data_type = \"numerical\"\n",
    "                    column_label = metadata[table_metadata_key][\"numerical_cols\"][column_name]\n",
    "                else:\n",
    "                    print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                if column_label == None:\n",
    "                    print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                valid_cols.append(column_name)\n",
    "                valid_labels.append(column_label)\n",
    "\n",
    "            df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "            if len(df_result) == 0:\n",
    "                print(f\"Table {table_name} ({idx_table_path}) has no columns with assigned semantic types!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                training_data[\"prompt\"] = df_result.to_csv(header=False)+end_of_prompt\n",
    "                training_data[\"completion\"] = \" \"+\"\\n\".join(valid_labels)\n",
    "                training_data_prompts.append(training_data)\n",
    "                all_class_labels.extend(valid_labels)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(valid_labels)\n",
    "                \n",
    "        with open(f\"./training_data/{sport_domain}_{split}_{shuffle_cols}_{random_state}.jsonl\", \"w\") as f:\n",
    "            for entry in training_data_prompts:\n",
    "                json.dump(entry, f)\n",
    "                f.write(\"\\n\")\n",
    "        print(f\"{sport_domain}_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data for gpt \n",
    "# Overall sport datasets\n",
    "\n",
    "sport_domains = [\"baseball\", \"basketball\", \"football\", \"hockey\", \"soccer\"]\n",
    "shuffle_cols = True\n",
    "random_state = 1\n",
    "split = \"test\"\n",
    "number_of_rows_per_table = 10\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,6):\n",
    "    training_data_prompts = []\n",
    "    all_class_labels = []\n",
    "    for sport_domain in sport_domains:\n",
    "        # load metadata.json containing semantic types of the columns\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, \"metadata.json\")) as f:\n",
    "            metadata = json.load(f)\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, f\"train_valid_test_split_{random_state}.json\")) as f:\n",
    "                    train_valid_test_split = json.load(f)\n",
    "                    \n",
    "        for idx_table_path, table_name_full in enumerate(train_valid_test_split[split]):\n",
    "            training_data = {}\n",
    "            # if idx_table_path > 2:\n",
    "            #     continue\n",
    "            table_name = table_name_full.split(\"/\")[-1].split(\".csv\")[0]\n",
    "            ## search for correct in key in metadata\n",
    "            table_metadata_key = None\n",
    "            for key in metadata.keys():\n",
    "                if key in table_name:\n",
    "                    table_metadata_key = key\n",
    "            if table_metadata_key == None:\n",
    "                #print(f\"CSV {table_name_full} not in metadata.json defined!\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(join(os.environ[\"SportsTables\"], sport_domain, table_name_full))\n",
    "            valid_cols = []\n",
    "            valid_labels = []\n",
    "            if shuffle_cols:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                #random.seed(self.random_state)\n",
    "                random.shuffle(column_list)\n",
    "            else:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                \n",
    "            for i in column_list:\n",
    "                column_name = df.columns[i]\n",
    "                # search for defined columns data type and semantic label in metadata\n",
    "                if column_name in metadata[table_metadata_key][\"textual_cols\"].keys():\n",
    "                    column_data_type = \"textual\"\n",
    "                    column_label = metadata[table_metadata_key][\"textual_cols\"][column_name]\n",
    "                elif column_name in metadata[table_metadata_key][\"numerical_cols\"].keys():\n",
    "                    column_data_type = \"numerical\"\n",
    "                    column_label = metadata[table_metadata_key][\"numerical_cols\"][column_name]\n",
    "                else:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                if column_label == None:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                valid_cols.append(column_name)\n",
    "                valid_labels.append(column_label)\n",
    "            \n",
    "            df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "            if len(df_result) == 0:\n",
    "                #print(f\"Table {table_name} has no columns with assigned semantic types!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                valid_labels = label_enc.transform(valid_labels)\n",
    "                training_data[\"prompt\"] = df_result.to_csv(header=False)+end_of_prompt\n",
    "                training_data[\"completion\"] = \" \"+\"\\n\".join([str(x) for x in valid_labels])\n",
    "                training_data_prompts.append(training_data)\n",
    "                all_class_labels.extend(valid_labels)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(valid_labels)\n",
    "                \n",
    "    with open(f\"./training_data/overall_{split}_{shuffle_cols}_{random_state}.jsonl\", \"w\") as f:\n",
    "        for entry in training_data_prompts:\n",
    "            json.dump(entry, f)\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"overall_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall / Tablewise transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data for gpt \n",
    "# Overall sport datasets\n",
    "# Now in the form of one row belongs to one column => transposed table\n",
    "\n",
    "sport_domains = [\"baseball\", \"basketball\", \"football\", \"hockey\", \"soccer\"]\n",
    "shuffle_cols = True\n",
    "random_state = 1\n",
    "split = \"test\"\n",
    "number_of_rows_per_table = 10\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,6):\n",
    "    training_data_prompts = []\n",
    "    all_class_labels = []\n",
    "    for sport_domain in sport_domains:\n",
    "        # load metadata.json containing semantic types of the columns\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, \"metadata.json\")) as f:\n",
    "            metadata = json.load(f)\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, f\"train_valid_test_split_{random_state}.json\")) as f:\n",
    "                    train_valid_test_split = json.load(f)\n",
    "                    \n",
    "        for idx_table_path, table_name_full in enumerate(train_valid_test_split[split]):\n",
    "            training_data = {}\n",
    "            # if idx_table_path > 250:\n",
    "            #     continue\n",
    "            table_name = table_name_full.split(\"/\")[-1].split(\".csv\")[0]\n",
    "            ## search for correct in key in metadata\n",
    "            table_metadata_key = None\n",
    "            for key in metadata.keys():\n",
    "                if key in table_name:\n",
    "                    table_metadata_key = key\n",
    "            if table_metadata_key == None:\n",
    "                #print(f\"CSV {table_name_full} not in metadata.json defined!\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(join(os.environ[\"SportsTables\"], sport_domain, table_name_full))\n",
    "            valid_cols = []\n",
    "            valid_labels = []\n",
    "            if shuffle_cols:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                #random.seed(self.random_state)\n",
    "                random.shuffle(column_list)\n",
    "            else:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                \n",
    "            for i in column_list:\n",
    "                column_name = df.columns[i]\n",
    "                # search for defined columns data type and semantic label in metadata\n",
    "                if column_name in metadata[table_metadata_key][\"textual_cols\"].keys():\n",
    "                    column_data_type = \"textual\"\n",
    "                    column_label = metadata[table_metadata_key][\"textual_cols\"][column_name]\n",
    "                elif column_name in metadata[table_metadata_key][\"numerical_cols\"].keys():\n",
    "                    column_data_type = \"numerical\"\n",
    "                    column_label = metadata[table_metadata_key][\"numerical_cols\"][column_name]\n",
    "                else:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                if column_label == None:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                valid_cols.append(column_name)\n",
    "                valid_labels.append(column_label)\n",
    "            \n",
    "            if len(valid_cols) == 0:\n",
    "                continue\n",
    "            df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "            if len(df_result) == 0:\n",
    "                #print(f\"Table {table_name} has no columns with assigned semantic types!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                valid_labels = label_enc.transform(valid_labels)\n",
    "                training_data[\"prompt\"] = df_result.T.to_csv(header=False, index=False)+end_of_prompt\n",
    "                training_data[\"completion\"] = \" \"+\"\\n\".join([str(x) for x in valid_labels])\n",
    "                training_data_prompts.append(training_data)\n",
    "                all_class_labels.extend(valid_labels)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(valid_labels)\n",
    "                \n",
    "    with open(f\"./training_data/overall_{split}_{shuffle_cols}_{random_state}_transposed.jsonl\", \"w\") as f:\n",
    "        for entry in training_data_prompts:\n",
    "            json.dump(entry, f)\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"overall_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall / Columnwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data for gpt \n",
    "# Overall sport datasets\n",
    "# Now in the form of one row belongs to one column => transposed table\n",
    "# Now in the form that one prompt/completion pair belongs to one table-column\n",
    "\n",
    "sport_domains = [\"baseball\", \"basketball\", \"football\", \"hockey\", \"soccer\"]\n",
    "shuffle_cols = True\n",
    "random_state = 1\n",
    "split = \"test\"\n",
    "number_of_rows_per_table = 10\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,6):\n",
    "    training_data_prompts = []\n",
    "    all_class_labels = []\n",
    "    for sport_domain in sport_domains:\n",
    "        # load metadata.json containing semantic types of the columns\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, \"metadata.json\")) as f:\n",
    "            metadata = json.load(f)\n",
    "        with open(join(os.environ[\"SportsTables\"], sport_domain, f\"train_valid_test_split_{random_state}.json\")) as f:\n",
    "                    train_valid_test_split = json.load(f)\n",
    "                    \n",
    "        for idx_table_path, table_name_full in enumerate(train_valid_test_split[split]):\n",
    "            # if idx_table_path > 0:\n",
    "            #     continue\n",
    "            table_name = table_name_full.split(\"/\")[-1].split(\".csv\")[0]\n",
    "            ## search for correct in key in metadata\n",
    "            table_metadata_key = None\n",
    "            for key in metadata.keys():\n",
    "                if key in table_name:\n",
    "                    table_metadata_key = key\n",
    "            if table_metadata_key == None:\n",
    "                #print(f\"CSV {table_name_full} not in metadata.json defined!\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(join(os.environ[\"SportsTables\"], sport_domain, table_name_full))\n",
    "            valid_cols = []\n",
    "            valid_labels = []\n",
    "            if shuffle_cols:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                #random.seed(self.random_state)\n",
    "                random.shuffle(column_list)\n",
    "            else:\n",
    "                column_list = list(range(len(df.columns)))\n",
    "                \n",
    "            for i in column_list:\n",
    "                column_name = df.columns[i]\n",
    "                # search for defined columns data type and semantic label in metadata\n",
    "                if column_name in metadata[table_metadata_key][\"textual_cols\"].keys():\n",
    "                    column_data_type = \"textual\"\n",
    "                    column_label = metadata[table_metadata_key][\"textual_cols\"][column_name]\n",
    "                elif column_name in metadata[table_metadata_key][\"numerical_cols\"].keys():\n",
    "                    column_data_type = \"numerical\"\n",
    "                    column_label = metadata[table_metadata_key][\"numerical_cols\"][column_name]\n",
    "                else:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                if column_label == None:\n",
    "                    #print(f\"Column {df.columns[i]} in {table_name} not labeled in metadata.json!\")\n",
    "                    continue\n",
    "                \n",
    "                valid_cols.append(column_name)\n",
    "                valid_labels.append(column_label)\n",
    "            \n",
    "            if len(valid_cols) == 0:\n",
    "                continue\n",
    "            df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "            if len(df_result) == 0:\n",
    "                #print(f\"Table {table_name} has no columns with assigned semantic types!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                for idx, column in enumerate(df_result.columns):\n",
    "                    training_data = {}\n",
    "                    training_data[\"prompt\"] = df_result[column].to_csv(header=False, index=False)+end_of_prompt\n",
    "                    training_data[\"completion\"] = \" \"+str(label_enc.transform([valid_labels[idx]])[0])\n",
    "                    training_data_prompts.append(training_data)\n",
    "                    all_class_labels.append(valid_labels[idx])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(valid_labels)\n",
    "                \n",
    "    with open(f\"./training_data/overall_{split}_{shuffle_cols}_{random_state}_columnwise.jsonl\", \"w\") as f:\n",
    "        for entry in training_data_prompts:\n",
    "            json.dump(entry, f)\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"overall_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ./training_data/overall_train_False_1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t ./training_data/GitTables_train_True_1_0.7_columnwise.jsonl -m ada --suffix GitTables-true-1-0.7-columnwise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "random_state = 1\n",
    "shuffle_cols = True\n",
    "sport_domain = \"overall\"\n",
    "modifications = \"transposed\"\n",
    "\n",
    "# load test data\n",
    "if modifications == None:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}.jsonl\", lines=True)\n",
    "else:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}_{modifications}.jsonl\", lines=True)\n",
    "\n",
    "model_dic = {\n",
    "    \"overall\": {\n",
    "        \"False\": {\n",
    "            \"1\": \"ada:ft-personal:overall-false-1-2023-03-27-15-30-00\",\n",
    "            \"2\": \"ada:ft-personal:overall-false-2-2023-03-27-17-27-58\"\n",
    "        },\n",
    "        \"True\": {\n",
    "            \"1\": \"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-2023-04-01-22-50-33\",\n",
    "            \"2\": \"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-2-2023-03-28-08-47-27\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_columnwise\":{\n",
    "        \"False\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-train-false-columnwisee-2023-03-30-21-05-01\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_transposed\":{\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-transposed-2023-04-02-19-57-41\"\n",
    "        }\n",
    "    },\n",
    "    \"baseball\": {\n",
    "        \"False\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-false-1-2023-03-28-22-19-35\"\n",
    "            },\n",
    "        \"True\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-true-1-2023-03-29-00-11-28\"\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "# load model\n",
    "if modifications == None:\n",
    "    model = model_dic[sport_domain][str(shuffle_cols)][str(random_state)]\n",
    "else:\n",
    "    model = model_dic[f\"{sport_domain}_{modifications}\"][str(shuffle_cols)][str(random_state)]\n",
    "print(f\"Loaded model: {model}\")  \n",
    "\n",
    "# test model\n",
    "total_true_labels = []\n",
    "total_predicted_labels = []\n",
    "for i in tqdm(range(0,len(test_dataset))):    \n",
    "    response = openai.Completion.create(\n",
    "        model= model,\n",
    "        temperature = 0.8,\n",
    "        max_tokens=600,\n",
    "        prompt= test_dataset.iloc[i][\"prompt\"]\n",
    "    )\n",
    "    number_of_predictions = len(test_dataset.iloc[i][\"completion\"].split(\"\\n\"))\n",
    "    true_labels = test_dataset.iloc[i][\"completion\"].split(\"\\n\")\n",
    "    true_labels[0] = true_labels[0].replace(\" \", \"\")\n",
    "    \n",
    "    predicted_labels = response[\"choices\"][0][\"text\"].split(\"\\n\")[:number_of_predictions]\n",
    "    predicted_labels[0] = predicted_labels[0].replace(\" \", \"\")\n",
    "    \n",
    "    if number_of_predictions != len(predicted_labels):\n",
    "        print(f\"Number of labels should be {number_of_predictions} but is {len(predicted_labels)}\")\n",
    "        print(i)\n",
    "        break\n",
    "        \n",
    "    total_true_labels.extend(true_labels)\n",
    "    total_predicted_labels.extend(predicted_labels)\n",
    "    \n",
    "class_report = classification_report(\n",
    "    total_true_labels, total_predicted_labels, output_dict=True)\n",
    "\n",
    "with open(f\"./results/classification_report_{sport_domain}_{shuffle_cols}_{random_state}_{modifications}.json\", \"w\") as f:\n",
    "    json.dump(class_report, f)\n",
    "    \n",
    "with open(f\"./results/predictions_{sport_domain}_{shuffle_cols}_{random_state}_{modifications}.json\", \"w\") as f:\n",
    "    json.dump({\"y_pred\":total_predicted_labels, \"y_true\":total_true_labels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test columnwise model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "random_state = 5\n",
    "shuffle_cols = True\n",
    "sport_domain = \"overall\"\n",
    "modifications = \"columnwise\"\n",
    "\n",
    "# load test data\n",
    "if modifications == None:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}.jsonl\", lines=True)\n",
    "else:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}_{modifications}.jsonl\", lines=True)\n",
    "\n",
    "model_dic = {\n",
    "    \"overall\": {\n",
    "        \"False\": {\n",
    "            \"1\": \"ada:ft-personal:overall-false-1-2023-03-27-15-30-00\",\n",
    "            \"2\": \"ada:ft-personal:overall-false-2-2023-03-27-17-27-58\"\n",
    "        },\n",
    "        \"True\": {\n",
    "            \"1\": \"ada:ft-personal:overall-true-1-2023-03-27-15-56-42\",\n",
    "            \"2\": \"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-2-2023-03-28-08-47-27\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_columnwise\":{\n",
    "        \"False\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-train-false-columnwisee-2023-03-30-21-05-01\"\n",
    "        },\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-columnwise-2023-04-03-13-31-50\",\n",
    "            \"2\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-2-columnwise-2023-04-01-22-43-04\",\n",
    "            \"3\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-3-columnwise-2023-06-10-01-13-49\",\n",
    "            \"4\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-4-columnwise-2023-06-10-01-39-44\",\n",
    "            \"5\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-5-columnwise-2023-06-10-02-05-42\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_transposed\":{\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-transposed-2023-03-30-20-13-28\"\n",
    "        }\n",
    "    },\n",
    "    \"baseball\": {\n",
    "        \"False\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-false-1-2023-03-28-22-19-35\"\n",
    "            },\n",
    "        \"True\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-true-1-2023-03-29-00-11-28\"\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "# load model\n",
    "if modifications == None:\n",
    "    model = model_dic[sport_domain][str(shuffle_cols)][str(random_state)]\n",
    "else:\n",
    "    model = model_dic[f\"{sport_domain}_{modifications}\"][str(shuffle_cols)][str(random_state)]\n",
    "print(f\"Loaded model: {model}\")  \n",
    "\n",
    "# test model\n",
    "total_true_labels = []\n",
    "total_predicted_labels = []\n",
    "for i in tqdm(range(0,len(test_dataset))):    \n",
    "    response = openai.Completion.create(\n",
    "        model= model,\n",
    "        temperature = 0.8,\n",
    "        max_tokens=1,\n",
    "        prompt= test_dataset.iloc[i][\"prompt\"]\n",
    "    )\n",
    "    #number_char_of_predictions = len(test_dataset.iloc[i][\"completion\"])\n",
    "    true_label = str(test_dataset.iloc[i][\"completion\"])\n",
    "    \n",
    "    #predicted_label = response[\"choices\"][0][\"text\"][:number_char_of_predictions]\n",
    "    predicted_label = response[\"choices\"][0][\"text\"].replace(\" \", \"\")\n",
    "        \n",
    "    total_true_labels.append(true_label)\n",
    "    total_predicted_labels.append(predicted_label)\n",
    "    \n",
    "class_report = classification_report(\n",
    "    total_true_labels, total_predicted_labels, output_dict=True)\n",
    "\n",
    "with open(f\"./results/classification_report_{sport_domain}_{shuffle_cols}_{random_state}_{modifications}.json\", \"w\") as f:\n",
    "    json.dump(class_report, f)\n",
    "    \n",
    "with open(f\"./results/predictions_{sport_domain}_{shuffle_cols}_{random_state}_{modifications}.json\", \"w\") as f:\n",
    "    json.dump({\"y_pred\":total_predicted_labels, \"y_true\":total_true_labels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "random_state = 1\n",
    "shuffle_cols = True\n",
    "sport_domain = \"overall\"\n",
    "modifications = \"columnwise\"\n",
    "\n",
    "# load test data\n",
    "if modifications == None:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}.jsonl\", lines=True)\n",
    "else:\n",
    "    test_dataset = pd.read_json(f\"./training_data/{sport_domain}_test_{shuffle_cols}_{random_state}_{modifications}.jsonl\", lines=True)\n",
    "\n",
    "model_dic = {\n",
    "    \"overall\": {\n",
    "        \"False\": {\n",
    "            \"1\": \"ada:ft-personal:overall-false-1-2023-03-27-15-30-00\",\n",
    "            \"2\": \"ada:ft-personal:overall-false-2-2023-03-27-17-27-58\"\n",
    "        },\n",
    "        \"True\": {\n",
    "            \"1\": \"ada:ft-personal:overall-true-1-2023-03-27-15-56-42\",\n",
    "            \"2\": \"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-2-2023-03-28-08-47-27\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_columnwise\":{\n",
    "        \"False\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-train-false-columnwisee-2023-03-30-21-05-01\"\n",
    "        },\n",
    "        \"True\":{\n",
    "            \"1\": \"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-columnwise-2023-04-01-21-14-53\"\n",
    "        }\n",
    "    },\n",
    "    \"overall_transposed\":{\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:overall-true-1-transposed-2023-03-30-20-13-28\"\n",
    "        }\n",
    "    },\n",
    "    \"baseball\": {\n",
    "        \"False\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-false-1-2023-03-28-22-19-35\"\n",
    "            },\n",
    "        \"True\": {\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:baseball-true-1-2023-03-29-00-11-28\"\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "# load model\n",
    "if modifications == None:\n",
    "    model = model_dic[sport_domain][str(shuffle_cols)][str(random_state)]\n",
    "else:\n",
    "    model = model_dic[f\"{sport_domain}_{modifications}\"][str(shuffle_cols)][str(random_state)]\n",
    "print(f\"Loaded model: {model}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dataset.iloc[27][\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset.iloc[0][\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "        model= model,\n",
    "        temperature = 0.8,\n",
    "        max_tokens=1,\n",
    "        prompt= test_dataset.iloc[27][\"prompt\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(response[\"choices\"][0][\"text\"].replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc.inverse_transform([55])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitTables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pyarrow.parquet as pq\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from tqdm import tqdm\n",
    "from column_annotation_gnn.data_loader.GitTables_data_loader import get_LabelEncoder\n",
    "\n",
    "label_enc = get_LabelEncoder()\n",
    "\n",
    "# tablewise\n",
    "shuffle_cols = True\n",
    "random_state = 1\n",
    "split = \"test\"\n",
    "number_of_rows_per_table = 10\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,2):\n",
    "    training_data_prompts = []\n",
    "    all_class_labels = []\n",
    "    with open(join(os.environ[\"GitTables\"], \"data\", f\"train_valid_test_split_{random_state}_0.7.json\")) as f:\n",
    "        train_valid_test_split = json.load(f)\n",
    "                \n",
    "    for idx_table_path, table_path in tqdm(enumerate(train_valid_test_split[split]), total=len(train_valid_test_split[split])):\n",
    "        training_data = {}\n",
    "        # if idx_table_path > 0:\n",
    "        #     continue\n",
    "        \n",
    "        # read metadata\n",
    "        table_metadata = json.loads(pq.read_schema(join(os.environ[\"GitTables\"], table_path)).metadata[b\"gittables\"])\n",
    "        dbpedia_types = table_metadata[\"dbpedia_embedding_column_types\"]\n",
    "        dbpedia_similarities = table_metadata[\"dbpedia_embedding_similarities\"]\n",
    "\n",
    "        # read the table in a DF\n",
    "        df = pd.read_parquet(join(os.environ[\"GitTables\"], table_path))\n",
    "            \n",
    "        valid_cols = []\n",
    "        valid_labels = []\n",
    "        if shuffle_cols:\n",
    "            column_list = list(range(len(df.columns)))\n",
    "            #random.seed(self.random_state)\n",
    "            random.shuffle(column_list)\n",
    "        else:\n",
    "            column_list = list(range(len(df.columns)))\n",
    "            \n",
    "        for i in column_list:\n",
    "            column_name = df.columns[i]\n",
    "            \n",
    "            try:\n",
    "                # check if the semantic type of the columns is in the valid semantic types that we consider in our experiments \n",
    "                if len(df[column_name].dropna()) > 0:\n",
    "                    if dbpedia_similarities[column_name] >= 0.7:\n",
    "                        if table_metadata[\"dtypes\"][column_name] == \"object\" or table_metadata[\"dtypes\"][column_name] == \"string\":\n",
    "                            if (dbpedia_types[column_name][\"cleaned_label\"]+\"_tt\" in label_enc.classes_):\n",
    "                                column_data_type = 0 # => \"textual\"\n",
    "                                column_label = dbpedia_types[column_name][\"cleaned_label\"]+\"_tt\"\n",
    "                            else:\n",
    "                                 continue\n",
    "                        else:\n",
    "                            if (dbpedia_types[column_name][\"cleaned_label\"]+\"_nt\" in label_enc.classes_):\n",
    "                                column_data_type = 1 # => \"numerical\"\n",
    "                                column_label = dbpedia_types[column_name][\"cleaned_label\"]+\"_nt\"\n",
    "                            else:\n",
    "                                continue\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                #print(e)\n",
    "                #print(f\"Not considering column: {column_name} from table: {table_path}\")\n",
    "            \n",
    "            valid_cols.append(column_name)\n",
    "            valid_labels.append(column_label)\n",
    "            \n",
    "        df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "        if len(df_result) == 0:\n",
    "            #print(f\"Table {table_name} has no columns with assigned semantic types!\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            valid_labels = label_enc.transform(valid_labels)\n",
    "            training_data[\"prompt\"] = df_result.to_csv(header=False)+end_of_prompt\n",
    "            training_data[\"completion\"] = \" \"+\"\\n\".join([str(x) for x in valid_labels])\n",
    "            training_data_prompts.append(training_data)\n",
    "            all_class_labels.extend(valid_labels)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(valid_labels)\n",
    "                \n",
    "    with open(f\"./training_data/GitTables_{split}_{shuffle_cols}_{random_state}_0.7.jsonl\", \"w\") as f:\n",
    "        for entry in training_data_prompts:\n",
    "            json.dump(entry, f)\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"overall_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnwise\n",
    "from os.path import join\n",
    "import pyarrow.parquet as pq\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from column_annotation_gnn.data_loader.GitTables_data_loader import get_LabelEncoder\n",
    "\n",
    "label_enc = get_LabelEncoder()\n",
    " \n",
    "# Generating training data for gpt \n",
    "# Overall sport datasets\n",
    "# Now in the form of one row belongs to one column => transposed table\n",
    "# Now in the form that one prompt/completion pair belongs to one table-column\n",
    "\n",
    "shuffle_cols = True\n",
    "random_state = 1\n",
    "split = \"train\"\n",
    "number_of_rows_per_table = 64\n",
    "end_of_prompt = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "for random_state in range(1,6):\n",
    "    training_data_prompts = []\n",
    "    all_class_labels = []\n",
    "    with open(join(os.environ[\"GitTables\"], \"data\", f\"train_valid_test_split_{random_state}.json\")) as f:\n",
    "        train_valid_test_split = json.load(f)\n",
    "                \n",
    "    for idx_table_path, table_path in tqdm(enumerate(train_valid_test_split[split], total=len(train_valid_test_split[split]))):\n",
    "        # if idx_table_path > 0:\n",
    "        #     continue\n",
    "        \n",
    "        # read metadata\n",
    "        table_metadata = json.loads(pq.read_schema(join(os.environ[\"GitTables\"], table_path)).metadata[b\"gittables\"])\n",
    "        dbpedia_types = table_metadata[\"dbpedia_embedding_column_types\"]\n",
    "        dbpedia_similarities = table_metadata[\"dbpedia_embedding_similarities\"]\n",
    "\n",
    "        # read the table in a DF\n",
    "        df = pd.read_parquet(join(os.environ[\"GitTables\"], table_path))\n",
    "            \n",
    "        valid_cols = []\n",
    "        valid_labels = []\n",
    "        if shuffle_cols:\n",
    "            column_list = list(range(len(df.columns)))\n",
    "            #random.seed(self.random_state)\n",
    "            random.shuffle(column_list)\n",
    "        else:\n",
    "            column_list = list(range(len(df.columns)))\n",
    "            \n",
    "        for i in column_list:\n",
    "            column_name = df.columns[i]\n",
    "            \n",
    "            try:\n",
    "                # check if the semantic type of the columns is in the valid semantic types that we consider in our experiments \n",
    "                if dbpedia_types[column_name][\"cleaned_label\"] in label_enc.classes_:\n",
    "                    # in case we want to filter assigned types regarding the similarity score later on\n",
    "                    if dbpedia_similarities[column_name] > 0.0: \n",
    "                        if table_metadata[\"dtypes\"][column_name] == \"object\" or table_metadata[\"dtypes\"][column_name] == \"string\":\n",
    "                            column_data_type = \"textual\"\n",
    "                            column_label = dbpedia_types[column_name][\"cleaned_label\"]\n",
    "                        else:\n",
    "                            column_data_type = \"numerical\"\n",
    "                            column_label = dbpedia_types[column_name][\"cleaned_label\"]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                #print(e)\n",
    "                \n",
    "                #print(f\"Not considering column: {column_name} from table: {table_path}\")\n",
    "            \n",
    "            valid_cols.append(column_name)\n",
    "            valid_labels.append(column_label)\n",
    "        \n",
    "        if len(valid_cols) == 0:\n",
    "            continue\n",
    "        if len(df_result) >= number_of_rows_per_table:\n",
    "            df_result = df[valid_cols][:number_of_rows_per_table]\n",
    "        else:\n",
    "            df_result = df[valid_cols]\n",
    "        if len(df_result) == 0:\n",
    "            #print(f\"Table {table_name} has no columns with assigned semantic types!\")\n",
    "            continue\n",
    "        try:\n",
    "            for idx, column in enumerate(df_result.columns):\n",
    "                training_data = {}\n",
    "                training_data[\"prompt\"] = df_result[column].to_csv(header=False, index=False)+end_of_prompt\n",
    "                training_data[\"completion\"] = \" \"+str(label_enc.transform([valid_labels[idx]])[0])\n",
    "                training_data_prompts.append(training_data)\n",
    "                all_class_labels.append(valid_labels[idx])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(valid_labels)\n",
    "                \n",
    "    with open(f\"./training_data/GitTables_{split}_{shuffle_cols}_{random_state}_columnwise.jsonl\", \"w\") as f:\n",
    "        for entry in training_data_prompts:\n",
    "            json.dump(entry, f)\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"GitTables_{split}_{shuffle_cols}_{random_state}.jsonl Number of unique classes: {len(np.unique(all_class_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test columnwise model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "random_state = 1\n",
    "shuffle_cols = True\n",
    "modifications = \"columnwise\"\n",
    "\n",
    "# load test data\n",
    "if modifications == None:\n",
    "    test_dataset = pd.read_json(f\"./training_data/GitTables_test_{shuffle_cols}_{random_state}.jsonl\", lines=True)\n",
    "else:\n",
    "    test_dataset = pd.read_json(f\"./training_data/GitTables_test_{shuffle_cols}_{random_state}_0.7_{modifications}.jsonl\", lines=True)\n",
    "\n",
    "model_dic = {\n",
    "    \"tablewise\": {\n",
    "        \"True\":{\n",
    "            \"1\": \"ada:ft-data-and-ai-systems-tu-darmstadt:gittables-true-1-0-7-2023-11-08-11-10-13\"\n",
    "        }\n",
    "    },\n",
    "    \"columnwise\":{\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:gittables-true-1-0-7-columnwise-2023-11-07-15-24-43\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# load model\n",
    "if modifications == None:\n",
    "    model = model_dic[\"tablewise\"][str(shuffle_cols)][str(random_state)]\n",
    "else:\n",
    "    model = model_dic[f\"{modifications}\"][str(shuffle_cols)][str(random_state)]\n",
    "print(f\"Loaded model: {model}\")  \n",
    "\n",
    "# test model\n",
    "total_true_labels = []\n",
    "total_predicted_labels = []\n",
    "for i in tqdm(range(0,len(test_dataset))):\n",
    "    # if i > 0:\n",
    "    #     break    \n",
    "    response = openai.Completion.create(\n",
    "        model= model,\n",
    "        temperature = 0.8,\n",
    "        max_tokens=600,\n",
    "        prompt= test_dataset.iloc[i][\"prompt\"]\n",
    "    )\n",
    "    # print(test_dataset.iloc[i][\"prompt\"])\n",
    "    # print(response)\n",
    "    #number_char_of_predictions = len(test_dataset.iloc[i][\"completion\"])\n",
    "    true_label = str(test_dataset.iloc[i][\"completion\"])\n",
    "    \n",
    "    #predicted_label = response[\"choices\"][0][\"text\"][:number_char_of_predictions]\n",
    "    predicted_label = response[\"choices\"][0][\"text\"].replace(\" \", \"\")\n",
    "        \n",
    "    total_true_labels.append(true_label)\n",
    "    total_predicted_labels.append(predicted_label)\n",
    "    \n",
    "class_report = classification_report(\n",
    "    total_true_labels, total_predicted_labels, output_dict=True)\n",
    "\n",
    "with open(f\"./results/GitTables_classification_report_{shuffle_cols}_{random_state}_0.7_{modifications}.json\", \"w\") as f:\n",
    "    json.dump(class_report, f)\n",
    "    \n",
    "with open(f\"./results/GitTables_predictions_{shuffle_cols}_{random_state}_0.7_{modifications}.json\", \"w\") as f:\n",
    "    json.dump({\"y_pred\":total_predicted_labels, \"y_true\":total_true_labels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test tablewise model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "random_state = 1\n",
    "shuffle_cols = True\n",
    "modifications = None\n",
    "\n",
    "# load test data\n",
    "if modifications == None:\n",
    "    test_dataset = pd.read_json(f\"./training_data/GitTables_test_{shuffle_cols}_{random_state}_0.7.jsonl\", lines=True)\n",
    "else:\n",
    "    test_dataset = pd.read_json(f\"./training_data/GitTables_test_{shuffle_cols}_{random_state}_0.7_{modifications}.jsonl\", lines=True)\n",
    "\n",
    "model_dic = {\n",
    "    \"tablewise\": {\n",
    "        \"True\":{\n",
    "            \"1\": \"ada:ft-data-and-ai-systems-tu-darmstadt:gittables-true-1-0-7-2023-11-08-11-10-13\"\n",
    "        }\n",
    "    },\n",
    "    \"columnwise\":{\n",
    "        \"True\":{\n",
    "            \"1\":\"ada:ft-data-and-ai-systems-tu-darmstadt:gittables-true-1-0-7-columnwise-2023-11-07-15-24-43\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# load model\n",
    "if modifications == None:\n",
    "    model = model_dic[\"tablewise\"][str(shuffle_cols)][str(random_state)]\n",
    "else:\n",
    "    model = model_dic[f\"{modifications}\"][str(shuffle_cols)][str(random_state)]\n",
    "print(f\"Loaded model: {model}\")  \n",
    "\n",
    "# test model\n",
    "total_true_labels = []\n",
    "total_predicted_labels = []\n",
    "for i in tqdm(range(0,len(test_dataset))):\n",
    "    # if i > 0:\n",
    "    #     break    \n",
    "    response = openai.Completion.create(\n",
    "        model= model,\n",
    "        temperature = 0.8,\n",
    "        max_tokens=600,\n",
    "        prompt= test_dataset.iloc[i][\"prompt\"]\n",
    "    )\n",
    "    number_of_predictions = len(test_dataset.iloc[i][\"completion\"].split(\"\\n\"))\n",
    "    true_labels = test_dataset.iloc[i][\"completion\"].split(\"\\n\")\n",
    "    true_labels[0] = true_labels[0].replace(\" \", \"\")\n",
    "    \n",
    "    predicted_labels = response[\"choices\"][0][\"text\"].split(\"\\n\")[:number_of_predictions]\n",
    "    predicted_labels[0] = predicted_labels[0].replace(\" \", \"\")\n",
    "    \n",
    "    if number_of_predictions != len(predicted_labels):\n",
    "        print(f\"Number of labels should be {number_of_predictions} but is {len(predicted_labels)}\")\n",
    "        print(i)\n",
    "        break\n",
    "        \n",
    "    total_true_labels.extend(true_labels)\n",
    "    total_predicted_labels.extend(predicted_labels)\n",
    "    \n",
    "class_report = classification_report(\n",
    "    total_true_labels, total_predicted_labels, output_dict=True)\n",
    "\n",
    "with open(f\"./results/GitTables_classification_report_{shuffle_cols}_{random_state}_0.7.json\", \"w\") as f:\n",
    "    json.dump(class_report, f)\n",
    "    \n",
    "with open(f\"./results/GitTables_predictions_{shuffle_cols}_{random_state}_0.7.json\", \"w\") as f:\n",
    "    json.dump({\"y_pred\":total_predicted_labels, \"y_true\":total_true_labels}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviation buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from openai import OpenAI\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "from data_loader.SportsDB_data_loader import get_all_numerical_semantic_types, get_all_textual_semantic_types\n",
    "\n",
    "semantic_types = get_all_textual_semantic_types()+get_all_numerical_semantic_types()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.retrieve(\"\")\n",
    "\n",
    "results = {}\n",
    "for i, semantic_type in enumerate(semantic_types):\n",
    "    # if i > 0:\n",
    "    #     continue\n",
    "    if len(semantic_type.split(\".\")) > 2:\n",
    "        user_message = \" \".join(semantic_type.split(\".\")[1:]).replace(\"_\", \" \")\n",
    "        print(user_message)\n",
    "    else:\n",
    "        user_message = semantic_type\n",
    "        print(user_message)\n",
    "\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    "    )\n",
    "    \n",
    "    completed = False\n",
    "    while completed == False:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if dict(run)[\"status\"] == \"completed\":\n",
    "            completed = True\n",
    "            \n",
    "    thread_messages = client.beta.threads.messages.list(thread.id)\n",
    "    results[semantic_type] = literal_eval(dict(thread_messages.data[0])[\"content\"][0].text.value)\n",
    "    \n",
    "    # save in each iteration the the results\n",
    "    with open(\"SportsTables_semantic_type_abbreviations.json\", \"w\") as f:\n",
    "        json.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
